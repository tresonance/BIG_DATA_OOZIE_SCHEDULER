######################################################
# job.properties
nameNode=hdfs://localhost:9000
jobTracker=localhost:8032
queueName=default
user.name=ibrahima
configSparkOptions=--executor-memory 4g --queue default --num-executors 4 --executor-cores 2 --driver-memory 4g --master yarn --conf spark.yarn.executor.memoryOverhead=512 --conf spark.yarn.driver.memoryOverhead=512 --conf spark.pyspark.driver.python=python3 --conf spark.pyspark.python=python3
myPythonPysparkScript=hdfs://localhost:9000/user/RUNS_OOZIE/scripts/python/create_dataframe.py
paramJsonFile=${nameNode}/user/RUNS_OOZIE/json/file.json
day="2023-09-12"
who=""
mode="TEST"
oozie.use.system.libpath=false
worflows_dir_ib_hdfsr=RUNS_OOZIE
#oozie.wf.application.path=${nameNode}/user/${worflows_dir_ib_hdfsr}/workflows/workflow_shell_single_action.xml
oozie.wf.application.path=${nameNode}/user/${worflows_dir_ib_hdfsr}/workflows/workflow_shell_single_action.xml
#oozie.wf.application.path=${nameNode}/user/${worflows_dir_ib_hdfs}/workflows/workflow_python_pyspark_single_action.xml
#oozie.wf.application.path=${nameNode}/user/${worflows_dir_ib_hdfs}/workflows/workflow_python_pyspark_multi_actions.xml
